{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## H2 trade analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "\n",
    "def H2_trade(file_path_scen,file_path_ref, run_name_scen,run_name_ref,output_folder):\n",
    "\n",
    "    var_Fout_ref = pd.read_csv(file_path_ref + 'VAR_FOut_' + run_name_ref + '.csv', sep = ',')\n",
    "    var_Fout_ref = var_Fout_ref[var_Fout_ref['1'] == 'HH2']\n",
    "    var_Fout_ref = var_Fout_ref[var_Fout_ref['2'] != 'H2_STG'] \n",
    "    var_Fout_ref['2'] = var_Fout_ref['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "    var_Fout_ref['2'] = var_Fout_ref['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "    var_Fout_ref['group_cnt'] = var_Fout_ref['4'].astype(str).str.cat(var_Fout_ref['3'].astype(str), sep='_')\n",
    "    var_Fout_sub_ref = var_Fout_ref[~var_Fout_ref['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_imp_ref = var_Fout_ref[var_Fout_ref['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_imp_ref = total_imp_ref.groupby('group_cnt')['8'].sum()/120\n",
    "    total_prod_ref = var_Fout_sub_ref.groupby('group_cnt')['8'].sum()/120\n",
    "\n",
    "    var_FIn_ref = pd.read_csv(file_path_ref + 'VAR_FIn_' + run_name_ref + '.csv', sep = ',')\n",
    "    var_FIn_ref = var_FIn_ref[var_FIn_ref['1'] == 'HH2']\n",
    "    var_FIn_ref = var_FIn_ref[var_FIn_ref['2'] != 'H2_STG']\n",
    "    var_FIn_ref['2'] = var_FIn_ref['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "    var_FIn_ref['2'] = var_FIn_ref['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "    var_FIn_ref['group_cnt'] = var_FIn_ref['4'].astype(str).str.cat(var_FIn_ref['3'].astype(str), sep='_')\n",
    "    var_FIn_sub_ref = var_FIn_ref[~var_FIn_ref['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_exp_ref = var_FIn_ref[var_FIn_ref['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "\n",
    "    total_exp_ref = total_exp_ref.groupby('group_cnt')['8'].sum()/120\n",
    "    total_cons_ref = var_FIn_sub_ref.groupby('group_cnt')['8'].sum()/120\n",
    "\n",
    "    total_net_exp_ref = pd.merge(total_prod_ref,total_cons_ref, how='inner',on='group_cnt').reset_index(drop=False).fillna(0)\n",
    "    total_net_exp_ref['net_exp'] = total_net_exp_ref['8_x'] - total_net_exp_ref['8_y']     # Example operation for negative numbers\n",
    "    total_net_exp_ref['share_imp'] = (total_net_exp_ref[total_net_exp_ref['net_exp'] < 0]['net_exp']/total_net_exp_ref[total_net_exp_ref['net_exp'] < 0]['8_y'])*100\n",
    "    total_net_exp_ref['share_exp'] = (total_net_exp_ref[total_net_exp_ref['net_exp'] > 0]['net_exp']/total_net_exp_ref[total_net_exp_ref['net_exp'] > 0]['8_x'])*100\n",
    "    total_net_exp_ref = total_net_exp_ref.fillna(0)\n",
    "    total_net_exp_ref['total_share'] = total_net_exp_ref['share_exp'] + total_net_exp_ref['share_imp']\n",
    "\n",
    "    def drop_last_substring(s):\n",
    "        substrings = s.split('_')\n",
    "        return '_'.join(substrings[:-1])\n",
    "    \n",
    "    \n",
    "    total_net_exp_ref['region'] = total_net_exp_ref['group_cnt'].apply(drop_last_substring)\n",
    "    total_net_exp_ref['mean_net_shr_exp'] = total_net_exp_ref.groupby('region')['total_share'].transform('mean')\n",
    "    \n",
    "\n",
    "    var_Fout_scen = pd.read_csv(file_path_scen + 'VAR_FOut_' + run_name_scen + '.csv', sep = ',')\n",
    "    var_Fout_scen = var_Fout_scen[var_Fout_scen['1'] == 'HH2']\n",
    "    var_Fout_scen = var_Fout_scen[var_Fout_scen['2'] != 'H2_STG'] \n",
    "    var_Fout_scen['2'] = var_Fout_scen['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "    var_Fout_scen['2'] = var_Fout_scen['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "    var_Fout_scen['group_cnt'] = var_Fout_scen['4'].astype(str).str.cat(var_Fout_scen['3'].astype(str), sep='_')\n",
    "    var_Fout_sub_scen = var_Fout_scen[~var_Fout_scen['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_imp_scen = var_Fout_scen[var_Fout_scen['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_imp_scen = total_imp_scen.groupby('group_cnt')['8'].sum()/120\n",
    "    total_prod_scen = var_Fout_sub_scen.groupby('group_cnt')['8'].sum()/120\n",
    "\n",
    "    var_FIn_scen = pd.read_csv(file_path_scen + 'VAR_FIn_' + run_name_scen + '.csv', sep = ',')\n",
    "    var_FIn_scen = var_FIn_scen[var_FIn_scen['1'] == 'HH2']\n",
    "    var_FIn_scen = var_FIn_scen[var_FIn_scen['2'] != 'H2_STG']\n",
    "    var_FIn_scen['2'] = var_FIn_scen['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "    var_FIn_scen['2'] = var_FIn_scen['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "    var_FIn_scen['group_cnt'] = var_FIn_scen['4'].astype(str).str.cat(var_FIn_scen['3'].astype(str), sep='_')\n",
    "    var_FIn_sub_sen = var_FIn_scen[~var_FIn_scen['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "    total_exp_scen = var_FIn_scen[var_FIn_scen['2'].isin(['TU_H2Pip*','TU_H2Ship*'])]\n",
    "\n",
    "    total_exp_scen = total_exp_scen.groupby('group_cnt')['8'].sum()/120\n",
    "    total_cons_scen = var_FIn_sub_sen.groupby('group_cnt')['8'].sum()/120\n",
    "\n",
    "    total_net_exp_scen = pd.merge(total_prod_scen,total_cons_scen, how='inner',on='group_cnt').reset_index(drop=False).fillna(0)\n",
    "    total_net_exp_scen['net_exp'] = total_net_exp_scen['8_x'] - total_net_exp_scen['8_y']     # Example operation for negative numbers\n",
    "    total_net_exp_scen['share_imp'] = (total_net_exp_scen[total_net_exp_scen['net_exp'] < 0]['net_exp']/total_net_exp_scen[total_net_exp_scen['net_exp'] < 0]['8_y'])*100\n",
    "    total_net_exp_scen['share_exp'] = (total_net_exp_scen[total_net_exp_scen['net_exp'] > 0]['net_exp']/total_net_exp_scen[total_net_exp_scen['net_exp'] > 0]['8_x'])*100\n",
    "    total_net_exp_scen = total_net_exp_scen.fillna(0)\n",
    "    total_net_exp_scen['total_share'] = total_net_exp_scen['share_exp'] + total_net_exp_scen['share_imp']\n",
    "\n",
    "    def drop_last_substring(s):\n",
    "        substrings = s.split('_')\n",
    "        return '_'.join(substrings[:-1])\n",
    "    \n",
    "    \n",
    "    total_net_exp_scen['region'] = total_net_exp_scen['group_cnt'].apply(drop_last_substring)\n",
    "    total_net_exp_scen['mean_net_shr_exp'] = total_net_exp_scen.groupby('region')['total_share'].transform('mean')\n",
    "\n",
    "\n",
    "\n",
    "    country_to_region = pd.read_excel('D:/Veda/Veda_models/kinesys_test - Copie/SubRes_Tmpl/SubRES_REZoning_Sol-Win_Trans.xlsx',sheet_name ='AVA')\n",
    "    country_to_region = country_to_region.iloc[3:].set_axis(country_to_region.iloc[2], axis=1).iloc[:,2:]\n",
    "    country_to_region['Country'] = ''\n",
    "\n",
    "    for index, row in country_to_region.iterrows():\n",
    "        parts = row['PSET_PN'].split('-')\n",
    "        country_to_region.at[index, 'Country'] = parts[1].strip()\n",
    "\n",
    "\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres')) \n",
    "\n",
    "    total_trade_map_ref = country_to_region.merge(total_net_exp_ref, how='outer', left_on='Region', right_on='region').reset_index(drop=True).fillna(0)\n",
    "    world_trade_map_ref = world.merge(total_trade_map_ref, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True).dropna()\n",
    "    world_trade_map_ref.shape\n",
    "\n",
    "    total_trade_map_scen = country_to_region.merge(total_net_exp_scen, how='outer', left_on='Region', right_on='region').reset_index(drop=True).fillna(0)\n",
    "    world_trade_map_scen = world.merge(total_trade_map_scen, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True).dropna()\n",
    "    total_trade_map_scen.shape\n",
    "\n",
    "\n",
    "    bwr_cmap = plt.cm.bwr\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    trade_map = world_trade_map_scen \n",
    "    colorbar_positions = [0.42, 0.2, 0.2, 0.02]\n",
    "    world.plot(ax=ax, color='white', edgecolor='black')\n",
    "    trade_map.plot(column='mean_net_shr_exp', cmap=bwr_cmap, linewidth=0.8, ax=ax, edgecolor='black', legend=False)\n",
    "\n",
    "    plt.title('Average H2 Net Export Share of the Production')\n",
    "    plt.ylim([-60, 90])\n",
    "    plt.axis('off')\n",
    "\n",
    "    min_val = trade_map['mean_net_shr_exp'].min()\n",
    "    max_val = trade_map['mean_net_shr_exp'].max()\n",
    "    norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "    ax_legend = fig.add_axes(colorbar_positions)\n",
    "    colorbar = ColorbarBase(ax_legend, cmap=bwr_cmap, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('H2 Net Export (%)')\n",
    "\n",
    "    plt.savefig(output_folder + 'H2net_export_map.pdf'\n",
    "            , format ='pdf',\n",
    "            bbox_inches='tight')\n",
    "    return plt\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # var_Fout['2'] = var_Fout['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "        # var_Fout['2'] = var_Fout['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "        # var_Fout['group'] = var_Fout['4'].astype(str).str.cat(var_Fout['3'].astype(str), sep='_').str.cat(var_Fout['2'].astype(str), sep='_')\n",
    "\n",
    "        \n",
    "        # var_FIn['2'] = var_FIn['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "        # var_FIn['2'] = var_FIn['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "        # var_FIn['group'] = var_FIn['4'].astype(str).str.cat(var_FIn['3'].astype(str), sep='_').str.cat(var_FIn['2'].astype(str), sep='_')\n",
    "\n",
    "        # H2_trade_merge = pd.merge(var_FIn,var_Fout, how='outer', on='group').reset_index(drop=True).fillna(0)\n",
    "        # H2_trade_merge = H2_trade_merge[~H2_trade_merge['group'].duplicated()]\n",
    "        # # return H2_trade_merge\n",
    "\n",
    "        # H2_prod['group_cnt'] = H2_prod['4'].astype(str).str.cat(H2_prod['3'].astype(str), sep='_')\n",
    "        # H2_prod['total_prod'] = H2_prod.groupby('group_cnt')['8'].transform('sum')/120\n",
    "\n",
    "        \n",
    "        # # H2_prod['8'] = pd.to_numeric(H2_prod['8'])\n",
    "        # H2_prod['TU_prod'] = H2_prod.groupby('group')['8'].transform('sum')/120\n",
    "        # # H2_prod = H2_prod[~H2_prod['group'].duplicated()]\n",
    "        # # H2_prod = H2_prod[H2_prod['2'].str.contains('TU_H2')]\n",
    "        # H2_prod = H2_prod[~H2_prod['group'].duplicated()]\n",
    "        # H2_prod['share_imp'] = H2_prod['TU_prod']/H2_prod['total_prod']*100\n",
    "        # H2_prod = H2_prod[['2','3','4','group_cnt','group','share_imp']]\n",
    "        # # return H2_prod\n",
    "        # # H2_prod['share_ships'] = H2_prod['TU_prod']/H2_prod['total_prod']*100\n",
    "\n",
    "\n",
    "        \n",
    "        # H2_cons['2'] = H2_cons['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "        # H2_cons['2'] = H2_cons['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "        # H2_cons['group_cnt'] = H2_cons['4'].astype(str).str.cat(H2_cons['3'].astype(str), sep='_')\n",
    "        # H2_cons['total_cons'] = H2_cons.groupby('group_cnt')['8'].transform('sum')/120\n",
    "        \n",
    "\n",
    "        # # H2_cons = H2_cons[~H2_cons['group'].duplicated()]\n",
    "        \n",
    "        # H2_cons['TU_cons'] = H2_cons.groupby('group')['8'].transform('sum')/120\n",
    "        # # H2_cons = H2_cons[H2_cons['2'].str.contains('TU_H2')]\n",
    "        # H2_cons = H2_cons[~H2_cons['group'].duplicated()]\n",
    "        # H2_cons['share_exp'] = H2_cons['TU_cons']/H2_cons['total_cons']*100\n",
    "        # H2_cons = H2_cons[['2','3','4','group_cnt','group','share_exp']]\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # # return H2_trade_merge\n",
    "        # H2_pip = H2_trade_merge[H2_trade_merge['2_x'] == 'TU_H2Pip*']\n",
    "        # H2_pip['net_pip_exp'] = H2_pip['share_exp'] - H2_pip['share_imp']\n",
    "\n",
    "        # H2_ships = H2_trade_merge[H2_trade_merge['2_x'] == 'TU_H2Ship*']\n",
    "        # H2_ships['net_ship_exp'] = H2_ships['share_exp'] - H2_ships['share_imp']\n",
    "\n",
    "        # # H2_ships['mean_ship_exp'] = H2_ships.groupby('4_x')['net_ship_exp'].transform('mean')\n",
    "        # # H2_ships = H2_ships[~H2_ships['4_x'].duplicated()]\n",
    "        # # return H2_ships\n",
    "        # # return H2_ships\n",
    "\n",
    "        # country_to_region = pd.read_excel('D:/Veda/Veda_models/kinesys_test - Copie/SubRes_Tmpl/SubRES_REZoning_Sol-Win_Trans.xlsx',sheet_name ='AVA')\n",
    "        # country_to_region = country_to_region.iloc[3:].set_axis(country_to_region.iloc[2], axis=1).iloc[:,2:]\n",
    "        # country_to_region['Country'] = ''\n",
    "\n",
    "        # for index, row in country_to_region.iterrows():\n",
    "        #     # Split the string in the original column based on the '-' symbol\n",
    "        #     parts = row['PSET_PN'].split('-')\n",
    "        #     # If there are two parts after splitting, assign the second part to the new column\n",
    "        #     country_to_region.at[index, 'Country'] = parts[1].strip()\n",
    "\n",
    "        # # country_to_region.head()\n",
    "\n",
    "        # H2ships_map = country_to_region.merge(H2_ships, how='outer', left_on='Region', right_on='4_x').reset_index(drop=True).fillna(0)\n",
    "        # H2ships_map = H2ships_map.dropna()\n",
    "        # H2ships_map['mean_ship_exp'] = H2ships_map.groupby('4_x')['net_ship_exp'].transform('mean')\n",
    "        \n",
    "\n",
    "        # H2pip_map = country_to_region.merge(H2_pip, how='outer', left_on='Region', right_on='4_x').reset_index(drop=True).fillna(0)\n",
    "        # H2pip_map = H2pip_map.dropna()\n",
    "        # H2pip_map['mean_pip_exp'] = H2pip_map.groupby('4_x')['net_pip_exp'].transform('mean')\n",
    "        \n",
    "\n",
    "        # ## map\n",
    "\n",
    "        # world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "        # world_H2pip_map = world.merge(H2pip_map, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True)\n",
    "        # world_H2pip_map.shape\n",
    "\n",
    "\n",
    "        # bwr_cmap = plt.cm.bwr\n",
    "        \n",
    "\n",
    "        # # Plot the map\n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "        # world.plot(ax=ax, color='white', edgecolor='black')\n",
    "        # world_H2pip_map.plot(column='mean_pip_exp', cmap=bwr_cmap, linewidth=0.8, ax=ax, edgecolor='black', legend=False)\n",
    "\n",
    "        # # Add title and customize plot\n",
    "        # plt.title('')\n",
    "        # plt.ylim([-60, 90])\n",
    "        # plt.axis('off')  # Turn off axis\n",
    "\n",
    "        # # Create a color bar\n",
    "        # # Create the colorbar\n",
    "        # min_val = world_H2pip_map['mean_pip_exp'].min()\n",
    "        # max_val = world_H2pip_map['mean_pip_exp'].max()\n",
    "        # norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "        # # Create an axis for the colorbar\n",
    "        # ax_legend = fig.add_axes([0.4, 0.2, 0.25, 0.02])  # [left, bottom, width, height]\n",
    "        # colorbar = ColorbarBase(ax_legend, cmap=bwr_cmap, norm=norm, orientation='horizontal')\n",
    "        # colorbar.set_label('Pipeline Net Export')\n",
    "\n",
    "\n",
    "\n",
    "        # ####\n",
    "        # world_H2ships_map= world.merge(H2ships_map, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True)\n",
    "        # world_H2ships_map.shape\n",
    "\n",
    "\n",
    "        # orange_cmap = plt.cm.Oranges\n",
    "\n",
    "        # # Plot the map\n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "        # world.plot(ax=ax, color='white', edgecolor='black')\n",
    "        # world_H2ships_map.plot(column='mean_ship_exp', cmap=bwr_cmap, linewidth=0.8, ax=ax, edgecolor='black', legend=False)\n",
    "\n",
    "        # # Add title and customize plot\n",
    "        # plt.title('')\n",
    "        # plt.ylim([-60, 90])\n",
    "        # plt.axis('off')  # Turn off axis\n",
    "\n",
    "        # # Create a color bar\n",
    "        # # Create the world_H2ships_map\n",
    "        # min_val = world_H2ships_map['mean_ship_exp'].min()\n",
    "        # max_val = world_H2ships_map['mean_ship_exp'].max()\n",
    "        # norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "        # # Create an axis for the colorbar\n",
    "        # ax_legend = fig.add_axes([0.4, 0.2, 0.25, 0.02])  # [left, bottom, width, height]\n",
    "        # colorbar = ColorbarBase(ax_legend, cmap=bwr_cmap, norm=norm, orientation='horizontal')\n",
    "        # colorbar.set_label('ships net export')\n",
    "\n",
    "        # return plt\n",
    "        # H2_prod['net_ships_exp'] = H2_prod['share_exp'] - H2_prod['share_imp']\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # H2_prod['group_cnt'] = H2_prod['4'].astype(str).str.cat(H2_prod['3'].astype(str), sep='_')\n",
    "        # H2_tot_prd = H2_prod.copy()\n",
    "        # H2_tot_prd['total_cons'] = H2_tot_prd.groupby('group_cnt')['8'].transform('sum')/120\n",
    "        # # H2_tot_prd = H2_tot_prd[~H2_tot_prd['group'].duplicated()]\n",
    "\n",
    "        # H2_prod_imp =  H2_prod[H2_prod['2'] == 'TU_H2Ship*']\n",
    "        # H2_prod_imp = H2_prod_imp[~H2_prod_imp['group'].duplicated()]\n",
    "        # H2_tot_prd = H2_tot_prd[~H2_tot_prd['group'].duplicated()]\n",
    "        # H2_prd_merge = H2_tot_prd.merge(H2_prod_imp, how='left', left_on='group_cnt', right_on='group_cnt').reset_index(drop=True).dropna()\n",
    "        # H2_prd_merge['share_pip'] = (H2_prd_merge['MtH2_y']/H2_prd_merge['total_cons'])*100\n",
    "\n",
    "        \n",
    "        # H2_prod_imp =  H2_prod[H2_prod['2'] == 'TU_H2Pip*']\n",
    "        # H2_prod_imp = H2_prod_imp[~H2_prod_imp['group'].duplicated()]\n",
    "        # H2_prd_merge1 = H2_tot_prd.merge(H2_prod_imp, how='outer', left_on='group_cnt', right_on='group_cnt').reset_index(drop=True)\n",
    "        # H2_prd_merge1['share_ships'] = (H2_prd_merge1['MtH2_y']/H2_prd_merge1['total_cons'])*100\n",
    "\n",
    "        # H2_ships = H2_prd_merge1[['3_x','4_x','share_ships']]\n",
    "        # H2_ships = H2_ships[H2_ships['3_x'] == 2050]\n",
    "        # H2_ships = H2_ships[~H2_ships.duplicated()]\n",
    "\n",
    "        # H2_pip = H2_prd_merge[['3_x','4_x','share_pip']]\n",
    "        # H2_pip = H2_pip[H2_pip['3_x'] == 2050]\n",
    "        # H2_pip = H2_pip[~H2_pip.duplicated()]\n",
    "\n",
    "        # var_FIn = pd.read_csv(file_path + 'VAR_FIn_' + run_name + '.csv', sep = ',')\n",
    "        # H2_cons = var_FIn[var_FIn['1'] == 'HH2']\n",
    "        # H2_cons = H2_cons[H2_cons['2'] != 'H2_STG']\n",
    "        # H2_cons['2'] = H2_cons['2'].str.replace(r'TU_H2Ship.*', 'TU_H2Ship*', regex=True)\n",
    "        # H2_cons['2'] = H2_cons['2'].str.replace(r'TU_H2Pip.*', 'TU_H2Pip*', regex=True)\n",
    "        # H2_cons['group'] = H2_cons['4'].astype(str).str.cat(H2_cons['3'].astype(str), sep='_').str.cat(H2_cons['2'].astype(str), sep='_')\n",
    "        # # H2_prod['8'] = pd.to_numeric(H2_prod['8'])\n",
    "        # H2_cons['MtH2'] = H2_cons.groupby('group')['8'].transform('sum')/120\n",
    "        # # H2_prod = H2_prod[~H2_prod['group'].duplicated()]\n",
    "\n",
    "        # H2_cons['group_cnt'] = H2_cons['4'].astype(str).str.cat(H2_cons['3'].astype(str), sep='_')\n",
    "        # H2_tot_cons = H2_cons.copy()\n",
    "        # H2_tot_cons['total_cons'] = H2_tot_cons.groupby('group_cnt')['8'].transform('sum')/120\n",
    "        # H2_tot_cons = H2_tot_cons[~H2_tot_cons['group'].duplicated()]\n",
    "\n",
    "        # H2_cons_exp =  H2_cons[H2_cons['2'] == 'TU_H2Ship*']\n",
    "        # H2_cons_exp = H2_cons_exp[~H2_cons_exp['group'].duplicated()]\n",
    "        # H2_cons_merge1 = H2_tot_cons.merge(H2_cons_exp, how='outer', left_on='group_cnt', right_on='group_cnt').reset_index(drop=True)\n",
    "        # H2_cons_merge1['share_ships'] = (H2_cons_merge1['MtH2_y']/H2_cons_merge1['total_cons'])*100\n",
    "\n",
    "        # H2_cons_exp =  H2_cons[H2_cons['2'] == 'TU_H2Pip*']\n",
    "        # H2_cons_exp = H2_cons_exp[~H2_cons_exp['group'].duplicated()]\n",
    "        # H2_cons_merge = H2_tot_cons.merge(H2_cons_exp, how='outer', left_on='group_cnt', right_on='group_cnt').reset_index(drop=True)\n",
    "        # H2_cons_merge['share_pip'] = (H2_cons_merge['MtH2_y']/H2_cons_merge['total_cons'])*100\n",
    "\n",
    "        # H2_pip_exp = H2_cons_merge[['3_x','4_x','share_pip']]\n",
    "        # H2_pip_exp = H2_pip_exp[H2_pip_exp['3_x'] == 2050]\n",
    "        # H2_pip_exp = H2_pip_exp[~H2_pip_exp.duplicated()]\n",
    "\n",
    "        # H2_ships_exp = H2_cons_merge1[['3_x','4_x','share_ships']]\n",
    "        # H2_ships_exp = H2_ships_exp[H2_ships_exp['3_x'] == 2050]\n",
    "        # H2_ships_exp = H2_ships_exp[~H2_ships_exp.duplicated()]\n",
    "\n",
    "        # H2_ships = H2_ships_exp.merge(H2_ships, how='outer', left_on='4_x', right_on='4_x').reset_index(drop=True).fillna(0)\n",
    "        # H2_ships['net_exp'] = H2_ships['share_ships_x'] - H2_ships['share_ships_y']\n",
    "        # # return H2_ships\n",
    "        # H2_pip = H2_pip_exp.merge(H2_pip, how='outer', left_on='4_x', right_on='4_x').reset_index(drop=True).fillna(0)\n",
    "        # H2_pip['net_exp'] =  H2_pip['share_pip_x'] - H2_pip['share_pip_y']\n",
    "        # # return H2_pip\n",
    "        \n",
    "        # # return H2_ships_exp\n",
    "\n",
    "        # country_to_region = pd.read_excel('D:/Veda/Veda_models/kinesys_test - Copie/SubRes_Tmpl/SubRES_REZoning_Sol-Win_Trans.xlsx',sheet_name ='AVA')\n",
    "        # country_to_region = country_to_region.iloc[3:].set_axis(country_to_region.iloc[2], axis=1).iloc[:,2:]\n",
    "        # country_to_region['Country'] = ''\n",
    "\n",
    "        # for index, row in country_to_region.iterrows():\n",
    "        #     # Split the string in the original column based on the '-' symbol\n",
    "        #     parts = row['PSET_PN'].split('-')\n",
    "        #     # If there are two parts after splitting, assign the second part to the new column\n",
    "        #     country_to_region.at[index, 'Country'] = parts[1].strip()\n",
    "\n",
    "        # # country_to_region.head()\n",
    "\n",
    "        # H2ships_map = country_to_region.merge(H2_ships, how='left', left_on='Region', right_on='4_x').reset_index(drop=True)\n",
    "        # H2ships_map = H2ships_map.dropna()\n",
    "\n",
    "        # H2pip_map = country_to_region.merge(H2_pip, how='left', left_on='Region', right_on='4_x').reset_index(drop=True)\n",
    "        # H2pip_map = H2pip_map.dropna()\n",
    "        \n",
    "\n",
    "        # ## map\n",
    "\n",
    "        # world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "        # world_H2pip_map = world.merge(H2pip_map, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True)\n",
    "        # world_H2pip_map.shape\n",
    "\n",
    "\n",
    "        # bwr_cmap = plt.cm.bwr\n",
    "        \n",
    "\n",
    "        # # Plot the map\n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "        # world.plot(ax=ax, color='white', edgecolor='black')\n",
    "        # world_H2pip_map.plot(column='net_exp', cmap=bwr_cmap, linewidth=0.8, ax=ax, edgecolor='black', legend=False)\n",
    "\n",
    "        # # Add title and customize plot\n",
    "        # plt.title('')\n",
    "        # plt.ylim([-60, 90])\n",
    "        # plt.axis('off')  # Turn off axis\n",
    "\n",
    "        # # Create a color bar\n",
    "        # # Create the colorbar\n",
    "        # min_val = world_H2pip_map['net_exp'].min()\n",
    "        # max_val = world_H2pip_map['net_exp'].max()\n",
    "        # norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "        # # Create an axis for the colorbar\n",
    "        # ax_legend = fig.add_axes([0.4, 0.2, 0.25, 0.02])  # [left, bottom, width, height]\n",
    "        # colorbar = ColorbarBase(ax_legend, cmap=bwr_cmap, norm=norm, orientation='horizontal')\n",
    "        # colorbar.set_label('Pipeline Net Export')\n",
    "\n",
    "\n",
    "\n",
    "        # ####\n",
    "        # world_H2ships_map= world.merge(H2ships_map, how='left', left_on='iso_a3', right_on='Country').reset_index(drop=True)\n",
    "        # world_H2ships_map.shape\n",
    "\n",
    "\n",
    "        # orange_cmap = plt.cm.Oranges\n",
    "\n",
    "        # # Plot the map\n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "        # world.plot(ax=ax, color='white', edgecolor='black')\n",
    "        # world_H2ships_map.plot(column='net_exp', cmap=bwr_cmap, linewidth=0.8, ax=ax, edgecolor='black', legend=False)\n",
    "\n",
    "        # # Add title and customize plot\n",
    "        # plt.title('')\n",
    "        # plt.ylim([-60, 90])\n",
    "        # plt.axis('off')  # Turn off axis\n",
    "\n",
    "        # # Create a color bar\n",
    "        # # Create the world_H2ships_map\n",
    "        # min_val = world_H2ships_map['net_exp'].min()\n",
    "        # max_val = world_H2ships_map['net_exp'].max()\n",
    "        # norm = Normalize(vmin=min_val, vmax=max_val)\n",
    "\n",
    "        # # Create an axis for the colorbar\n",
    "        # ax_legend = fig.add_axes([0.4, 0.2, 0.25, 0.02])  # [left, bottom, width, height]\n",
    "        # colorbar = ColorbarBase(ax_legend, cmap=bwr_cmap, norm=norm, orientation='horizontal')\n",
    "        # colorbar.set_label('ships net export')\n",
    "\n",
    "# H2_trade(file_path_scen,file_path_ref, run_name_scen,run_name_ref)\n",
    "        # return H2_trade_df\n",
    "       \n",
    "        # values1 = np.linspace(0, 1, 20)\n",
    "        # values2 = np.linspace(0, 1, 9)\n",
    "        # # Create two colormaps\n",
    "        # cmap1 = plt.cm.tab20\n",
    "        # cmap2 = plt.cm.Set3\n",
    "\n",
    "\n",
    "        # colors1 = cmap1(values1)\n",
    "        # colors2 = cmap2(values2)\n",
    "\n",
    "\n",
    "\n",
    "        # # Combine the colors from both colormaps\n",
    "        # combined_colors = np.vstack((colors1, colors2))\n",
    "\n",
    "        # # Create a new colormap using the combined colors\n",
    "        # combined_cmap = ListedColormap(combined_colors)\n",
    "        # # cmap = ListedColormap(color_map(np.arange(num_unique)))\n",
    "\n",
    "        # pivot_df = H2_ships.pivot(index='3_x', columns='4_x', values='share_ships')\n",
    "        # column_sums = pivot_df.sum(skipna=True)\n",
    "\n",
    "        # # Step 2: Sort the columns based on their sums\n",
    "        # sorted_columns = column_sums.sort_values(ascending=False)\n",
    "\n",
    "        # # Step 3: Reindex the DataFrame with the sorted column order\n",
    "        # sorted_df = pivot_df.reindex(sorted_columns.index, axis=1)\n",
    "        \n",
    "        # # sorted_df.head()\n",
    "        # # Plot with the discrete color map\n",
    "        # sorted_df.plot(kind='line', colormap=combined_cmap)\n",
    "        # plt.legend(title='', bbox_to_anchor=(0.5, -0.62), loc = 'lower center', ncol=4)\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.xticks(rotation=0)\n",
    "        # plt.ylabel('MtH2')\n",
    "        # plt.title('Share Pipeline')\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # pivot_df1 = H2_pip.pivot(index='3_x', columns='4_x', values='share_pip')\n",
    "        # column_sums = pivot_df1.sum(skipna=True)\n",
    "\n",
    "        # # Step 2: Sort the columns based on their sums\n",
    "        # sorted_columns = column_sums.sort_values(ascending=False)\n",
    "\n",
    "        # # Step 3: Reindex the DataFrame with the sorted column order\n",
    "        # sorted_df = pivot_df1.reindex(sorted_columns.index, axis=1)\n",
    "        # # sorted_df.head()\n",
    "        # # Plot with the discrete color map\n",
    "        # sorted_df.plot(kind='line', colormap=combined_cmap)\n",
    "        # plt.legend(title='', bbox_to_anchor=(0.5, -0.62), loc = 'lower center', ncol=4)\n",
    "        # plt.xlabel('Year')\n",
    "        # plt.xticks(rotation=0)\n",
    "        # plt.ylabel('MtH2')\n",
    "        # plt.title('Share ships')\n",
    "        # plt.show()\n",
    "    # plt.tight_layout()\n",
    "        # plt.savefig(output_folder + 'H2_prod_country.pdf'\n",
    "        #             , format ='pdf'\n",
    "        #             ,  bbox_inches='tight')\n",
    "\n",
    "    # return H2_prd_merge"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
